{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Activation, Convolution2D, Dropout, Conv2D\n",
    "from keras.layers import AveragePooling2D, BatchNormalization\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Flatten\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import SeparableConv2D\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from livelossplot.inputs.tf_keras import PlotLossesCallback\n",
    "from keras import layers\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from keras.regularizers import l2\n",
    "\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size=(48,48)\n",
    "def dataset_loader():\n",
    "    df = pd.read_csv(\"fer2013.csv\")\n",
    "    width, height = 48, 48\n",
    "    pics = []\n",
    "    for pix in df[\"pixels\"]:\n",
    "        pic = [int(pixel) for pixel in pix.split(' ')]\n",
    "        pic = np.asarray(pic).reshape(width, height)\n",
    "        pic = cv2.resize(pic.astype('uint8'),image_size)\n",
    "        pics.append(pic.astype('float32'))\n",
    "    pics = np.asarray(pics)\n",
    "    pics = np.expand_dims(pics, -1)\n",
    "    emo = pd.get_dummies(df['emotion']).values\n",
    "    return pics, emo,df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x, v2=True):\n",
    "    x = x.astype('float32')\n",
    "    x = x / 255.0\n",
    "    if v2:\n",
    "        x = x - 0.5\n",
    "        x = x * 2.0\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating of the metrics for model evaluation\n",
    "def recall_m(actual, predicted):\n",
    "    tp = K.sum(K.round(K.clip(actual * predicted, 0, 1)))\n",
    "    positive_posible = K.sum(K.round(K.clip(actual, 0, 1)))\n",
    "    recall = tp / (positive_posible + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(actual, predicted):\n",
    "    tp = K.sum(K.round(K.clip(actual * predicted, 0, 1)))\n",
    "    positive_posible = K.sum(K.round(K.clip(predicted, 0, 1)))\n",
    "    precision = tp / (positive_posible + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_score(actual, predicted):\n",
    "    precision = precision_m(actual, predicted)\n",
    "    recall = recall_m(actual, predicted)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split():\n",
    "    #Loading of dataset\n",
    "    df = pd.read_csv(\"fer2013.csv\")\n",
    "    \n",
    "    batch_size = 32\n",
    "    num_epochs = 150\n",
    "    input_shape = (48, 48, 1)\n",
    "    verbose = 1\n",
    "    num_classes = 7\n",
    "    patience = 50\n",
    "    path = 'models/'\n",
    "    l2_regularization=0.01\n",
    "    height = 48\n",
    "    width = 48\n",
    "    \n",
    "    #dividing data into two format for training and test\n",
    "    training_data = df[[\"emotion\", \"pixels\"]][(df[\"Usage\"] == \"Training\")]\n",
    "    testing_data = df[[\"emotion\", \"pixels\"]][(df[\"Usage\"] == \"PublicTest\")]\n",
    "    \n",
    "    X_train,train_y,X_test,test_y=[],[],[],[]\n",
    "    \n",
    "    # Passing the respected data into X_train,train_y,X_test,test_y\n",
    "    for x,y in training_data.iterrows():\n",
    "        val=y['pixels'].split(\" \")\n",
    "        X_train.append(np.array(val,'float32'))\n",
    "        train_y.append(y['emotion'])\n",
    "\n",
    "    for index,row in testing_data.iterrows():\n",
    "        val=row['pixels'].split(\" \")\n",
    "        X_test.append(np.array(val,'float32'))\n",
    "        test_y.append(row['emotion'])\n",
    "        \n",
    "    #Changing the entire array of numpy array into float 32\n",
    "    X_train = np.array(X_train,'float32')\n",
    "    train_y = np.array(train_y,'float32')\n",
    "    X_test = np.array(X_test,'float32')\n",
    "    test_y = np.array(test_y,'float32')\n",
    "    \n",
    "    # Data normalization\n",
    "    X_train = X_train - np.mean(X_train, axis=0)\n",
    "    X_test = X_test - np.mean(X_test, axis=0)\n",
    "    X_train = X_train / np.std(X_train, axis=0)\n",
    "    X_test = X_test / np.std(X_test, axis=0)\n",
    "    \n",
    "    #Reshaping of data\n",
    "    X_train = X_train.reshape(X_train.shape[0],48, 48,1)\n",
    "    X_test = X_test.reshape(X_test.shape[0],48, 48 , 1)\n",
    "\n",
    "    train_y = np_utils.to_categorical(train_y, num_classes=7)\n",
    "    test_y = np_utils.to_categorical(test_y, num_classes=7)\n",
    "    return X_train,train_y,X_test,test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,normalize=False,title='Confusion matrix',cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
